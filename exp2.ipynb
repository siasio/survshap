{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurvSHAP(t): Time-Dependent Explanations Of Machine Learning Survival Models\n",
    "### M. Krzyzi≈Ñski, M. Spytek, H. Baniecki, P. Biecek\n",
    "## Experiment 2: Comparison to SurvLIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sksurv.util import Surv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data and models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_train = pd.read_csv(\"data/exp2_dataset0_train.csv\")\n",
    "dataset0_test = pd.read_csv(\"data/exp2_dataset0_test.csv\")\n",
    "X_train0 = dataset0_train.iloc[:, :5]\n",
    "X_test0 = dataset0_test.iloc[:, :5]\n",
    "y_train0 = Surv.from_dataframe(\"event\", \"time\", dataset0_train)\n",
    "y_test0 = Surv.from_dataframe(\"event\", \"time\", dataset0_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_train = pd.read_csv(\"data/exp2_dataset1_train.csv\")\n",
    "dataset1_test = pd.read_csv(\"data/exp2_dataset1_test.csv\")\n",
    "X_train1 = dataset1_train.iloc[:, :5]\n",
    "X_test1 = dataset1_test.iloc[:, :5]\n",
    "y_train1 = Surv.from_dataframe(\"event\", \"time\", dataset1_train)\n",
    "y_test1 = Surv.from_dataframe(\"event\", \"time\", dataset1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "cph_dataset0 = CoxPHSurvivalAnalysis()\n",
    "cph_dataset0.fit(X_train0, y_train0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_dataset1 = CoxPHSurvivalAnalysis()\n",
    "cph_dataset1.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading explanations\n",
    "##### SurvLIME dataset0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp2_survlime_dataset0_cph\", \"rb\") as f:\n",
    "    exp2_survlime_dataset0_cph = pickle.load(f)\n",
    "with open(\"pickles/exp2_survlime_dataset0_rsf\", \"rb\") as f:\n",
    "    exp2_survlime_dataset0_rsf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SurvLIME dataset1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp2_survlime_dataset1_cph\", \"rb\") as f:\n",
    "    exp2_survlime_dataset1_cph = pickle.load(f)\n",
    "with open(\"pickles/exp2_survlime_dataset1_rsf\", \"rb\") as f:\n",
    "    exp2_survlime_dataset1_rsf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SurvSHAP(t) dataset0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp2_survshap_dataset0_cph\", \"rb\") as f:\n",
    "    exp2_survshap_dataset0_cph = pickle.load(f)\n",
    "with open(\"pickles/exp2_survshap_dataset0_rsf\", \"rb\") as f:\n",
    "    exp2_survshap_dataset0_rsf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SurvSHAP(t) dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pickles/exp2_survshap_dataset1_cph\", \"rb\") as file:\n",
    "    exp2_survshap_dataset1_cph = pickle.load(file)\n",
    "with open(\"pickles/exp2_survshap_dataset1_rsf\", \"rb\") as file:\n",
    "    exp2_survshap_dataset1_rsf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_accuracy_from_shap_explanations(all_explanations, method_label, cluster_label, model_label, last_index=None):\n",
    "    if last_index is None:\n",
    "        last_index=len(all_explanations[0].timestamps)\n",
    "    diffs = []\n",
    "    preds = []\n",
    "    for explanation in all_explanations:\n",
    "        preds.append(explanation.predicted_function[:last_index])\n",
    "        diffs.append(explanation.predicted_function[:last_index] - explanation.baseline_function[:last_index] - np.array(explanation.result.iloc[:, 5:].sum(axis=0))[:last_index])\n",
    "    diffs_squared = np.array(diffs)**2\n",
    "    E_diffs_squared = np.mean(diffs_squared, axis=0)\n",
    "    preds_squared = np.array(preds)**2\n",
    "    E_preds_squared = np.mean(preds_squared, axis=0)\n",
    "    return  pd.DataFrame({\"time\": all_explanations[0].timestamps[:last_index], \"sigma\": np.sqrt(E_diffs_squared) / np.sqrt(E_preds_squared), \n",
    "     \"method\": method_label, \"cluster\": cluster_label, \"model\": model_label })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_accuracy_from_lime_explanations(all_explanations, method_label, cluster_label, model_label, last_index=None):\n",
    "    if last_index is None:\n",
    "        last_index=len(all_explanations[0].timestamps)\n",
    "    diffs = []\n",
    "    preds = []\n",
    "    for explanation in all_explanations:\n",
    "        preds.append(explanation.predicted_sf[:last_index])\n",
    "        diffs.append(explanation.predicted_sf[:last_index] - np.array(explanation.survlime_sf[:last_index]))\n",
    "    diffs_squared = np.array(diffs)**2\n",
    "    E_diffs_squared = np.mean(diffs_squared, axis=0)\n",
    "    preds_squared = np.array(preds)**2\n",
    "    E_preds_squared = np.mean(preds_squared, axis=0)\n",
    "    return  pd.DataFrame({\"time\": all_explanations[0].timestamps[:last_index], \"sigma\": np.sqrt(E_diffs_squared) / np.sqrt(E_preds_squared), \n",
    "    \"method\": method_label, \"cluster\": cluster_label, \"model\": model_label })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_shap_cph_cluster_0 = get_local_accuracy_from_shap_explanations(exp2_survshap_dataset0_cph, \"shap\", \"0\", \"cph\")\n",
    "local_accuracy_lime_cph_cluster_0 = get_local_accuracy_from_lime_explanations(exp2_survlime_dataset0_cph, \"lime\", \"0\", \"cph\")\n",
    "\n",
    "pd.concat([local_accuracy_shap_cph_cluster_0, local_accuracy_lime_cph_cluster_0]).to_csv(\"results/exp2_local_accuracy_cph_dataset0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_shap_cph_cluster_1 = get_local_accuracy_from_shap_explanations(exp2_survshap_dataset1_cph, \"shap\", \"1\", \"cph\")\n",
    "local_accuracy_lime_cph_cluster_1 = get_local_accuracy_from_lime_explanations(exp2_survlime_dataset1_cph, \"lime\", \"1\", \"cph\")\n",
    "\n",
    "pd.concat([local_accuracy_shap_cph_cluster_1, local_accuracy_lime_cph_cluster_1]).to_csv(\"results/exp2_local_accuracy_cph_dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_shap_rsf_cluster_0 = get_local_accuracy_from_shap_explanations(exp2_survshap_dataset0_rsf, \"shap\", \"0\", \"rsf\")\n",
    "local_accuracy_lime_rsf_cluster_0 = get_local_accuracy_from_lime_explanations(exp2_survlime_dataset0_rsf, \"lime\", \"0\", \"rsf\")\n",
    "\n",
    "pd.concat([local_accuracy_shap_rsf_cluster_0, local_accuracy_lime_rsf_cluster_0]).to_csv(\"results/exp2_local_accuracy_rsf_dataset0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_accuracy_shap_rsf_cluster_1 = get_local_accuracy_from_shap_explanations(exp2_survshap_dataset1_rsf, \"shap\", \"1\", \"rsf\")\n",
    "local_accuracy_lime_rsf_cluster_1 = get_local_accuracy_from_lime_explanations(exp2_survlime_dataset1_rsf, \"lime\", \"1\", \"rsf\")\n",
    "\n",
    "pd.concat([local_accuracy_shap_rsf_cluster_1, local_accuracy_lime_rsf_cluster_1]).to_csv(\"results/exp2_local_accuracy_rsf_dataset1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orderings_and_ranks_lime(explanations):\n",
    "    importance_orderings = []\n",
    "    importance_ranks = []\n",
    "    for explanation in explanations:\n",
    "        df = explanation.result\n",
    "        df[\"impact\"] = df[\"variable_value\"] * df[\"coefficient\"] \n",
    "        importance_orderings.append(df.sort_values(by=\"impact\", key=lambda x: -abs(x)).index.to_list())\n",
    "        importance_ranks.append(np.abs(df.impact).rank(ascending=False).to_list())\n",
    "    return pd.DataFrame(importance_orderings), pd.DataFrame(importance_ranks)\n",
    "\n",
    "from scipy.integrate import trapezoid    \n",
    "def get_orderings_and_ranks_shap(explanations):\n",
    "    importance_orderings = []\n",
    "    importance_ranks = []\n",
    "    for explanation in explanations:\n",
    "        df = explanation.result.copy()\n",
    "        df[\"aggregated_change\"] = trapezoid(np.abs(df.iloc[:, 5:].values), explanation.timestamps)\n",
    "        importance_orderings.append(df.sort_values(by=\"aggregated_change\", key=lambda x: -abs(x)).index.to_list())\n",
    "        importance_ranks.append(np.abs(df.aggregated_change).rank(ascending=False).to_list())\n",
    "    return pd.DataFrame(importance_orderings), pd.DataFrame(importance_ranks)\n",
    "\n",
    "from scipy.stats import weightedtau\n",
    "def mean_weighted_tau(ranks1, ranks2):\n",
    "    taus = [None] * 100\n",
    "    for i in range(100):\n",
    "        tau, _ = weightedtau(ranks1.iloc[i], ranks2.iloc[i])\n",
    "        taus[i] = tau\n",
    "    return np.mean(taus)\n",
    "\n",
    "def prepare_ranking_summary_long(ordering):\n",
    "    res = pd.DataFrame(columns=[0, 1, 2, 3, 4])\n",
    "    for i in range(5):\n",
    "        tmp = pd.DataFrame(ordering[i].value_counts().to_dict(), index=[i+1])\n",
    "        res = pd.concat([res, tmp])\n",
    "    res = res.reset_index().rename(columns={0: \"x1\", 1: \"x2\", 2: \"x3\", 3: \"x4\", 4: \"x5\", \"index\": \"importance_ranking\"})\n",
    "    return res.melt(id_vars=[\"importance_ranking\"], value_vars=[\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dataset0\n",
    "- $\\beta^T = [10^{‚àí6}, 0.1, -0.15, 10^{‚àí6}, 10^{‚àí6}]$\n",
    "- ranking (by index): [0/3/4, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_dataset0.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_cph_survlime_orderings, dataset0_cph_survlime_ranks = get_orderings_and_ranks_lime(exp2_survlime_dataset0_cph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/3/4)\")\n",
    "print(dataset0_cph_survlime_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (1)\")\n",
    "print(dataset0_cph_survlime_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (2)\")\n",
    "print(dataset0_cph_survlime_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset0_cph_survlime_orderings).to_csv(\"results/exp2_survlime_orderings_cph_dataset0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_cph_survshap_orderings, dataset0_cph_survshap_ranks = get_orderings_and_ranks_shap(exp2_survshap_dataset0_cph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/3/4)\")\n",
    "print(dataset0_cph_survshap_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (1)\")\n",
    "print(dataset0_cph_survshap_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (2)\")\n",
    "print(dataset0_cph_survshap_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset0_cph_survshap_orderings).to_csv(\"results/exp2_survshap_orderings_cph_dataset0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT CPH\n",
    "importance_ranks = []\n",
    "for i, row in X_test0.iterrows():\n",
    "    impact = row * cph_dataset0.coef_\n",
    "    importance_ranks.append(np.abs(impact).rank(ascending=False).to_list())\n",
    "dataset0_cph_true_ranks = pd.DataFrame(importance_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset0_cph_survlime_ranks, dataset0_cph_survshap_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset0_cph_survlime_ranks, dataset0_cph_true_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset0_cph_survshap_ranks, dataset0_cph_true_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_rsf_survlime_orderings, dataset0_rsf_survlime_ranks = get_orderings_and_ranks_lime(exp2_survlime_dataset0_rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/3/4)\")\n",
    "print(dataset0_rsf_survlime_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (1)\")\n",
    "print(dataset0_rsf_survlime_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (2)\")\n",
    "print(dataset0_rsf_survlime_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset0_rsf_survlime_orderings).to_csv(\"results/exp2_survlime_orderings_rsf_dataset0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset0_rsf_survshap_orderings, dataset0_rsf_survshap_ranks = get_orderings_and_ranks_shap(exp2_survshap_dataset0_rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/3/4)\")\n",
    "print(dataset0_rsf_survshap_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (1)\")\n",
    "print(dataset0_rsf_survshap_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (2)\")\n",
    "print(dataset0_rsf_survshap_orderings[0].value_counts())\n",
    "prepare_ranking_summary_long(dataset0_rsf_survshap_orderings).to_csv(\"results/exp2_survshap_orderings_rsf_dataset0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dataset1\n",
    "- $\\beta^T = [10^{‚àí6}, ‚àí0.15, 10^{‚àí6}, 10^{‚àí6}, ‚àí0.1]$\n",
    "- ranking (by index): [0/2/3, 4, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph_dataset1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_cph_survlime_orderings, dataset1_cph_survlime_ranks = get_orderings_and_ranks_lime(exp2_survlime_dataset1_cph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/2/3)\")\n",
    "print(dataset1_cph_survlime_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (4)\")\n",
    "print(dataset1_cph_survlime_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (1)\")\n",
    "print(dataset1_cph_survlime_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset1_cph_survlime_orderings).to_csv(\"results/exp2_survlime_orderings_cph_dataset1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_cph_survshap_orderings, dataset1_cph_survshap_ranks = get_orderings_and_ranks_shap(exp2_survshap_dataset1_cph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/2/3)\")\n",
    "print(dataset1_cph_survshap_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (4)\")\n",
    "print(dataset1_cph_survshap_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (1)\")\n",
    "print(dataset1_cph_survshap_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset1_cph_survshap_orderings).to_csv(\"results/exp2_survshap_orderings_cph_dataset1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT CPH\n",
    "importance_ranks = [] \n",
    "for i, row in X_test1.iterrows():\n",
    "    impact = row * cph_dataset1.coef_\n",
    "    importance_ranks.append(np.abs(impact).rank(ascending=False).to_list())\n",
    "dataset1_cph_true_ranks = pd.DataFrame(importance_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset1_cph_survlime_ranks, dataset1_cph_survshap_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset1_cph_survlime_ranks, dataset1_cph_true_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weighted_tau(dataset1_cph_survshap_ranks, dataset1_cph_true_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_rsf_survlime_orderings, dataset1_rsf_survlime_ranks = get_orderings_and_ranks_lime(exp2_survlime_dataset1_rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/2/3)\")\n",
    "print(dataset1_rsf_survlime_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (4)\")\n",
    "print(dataset1_rsf_survlime_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (1)\")\n",
    "print(dataset1_rsf_survlime_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset1_rsf_survlime_orderings).to_csv(\"results/exp2_survlime_orderings_rsf_dataset1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_rsf_survshap_orderings, dataset1_rsf_survshap_ranks = get_orderings_and_ranks_shap(exp2_survshap_dataset1_rsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The least important (0/2/3)\")\n",
    "print(dataset1_rsf_survshap_orderings[4].value_counts())\n",
    "\n",
    "print(\"The second most important (4)\")\n",
    "print(dataset1_rsf_survshap_orderings[1].value_counts())\n",
    "\n",
    "print(\"The most important (1)\")\n",
    "print(dataset1_rsf_survshap_orderings[0].value_counts())\n",
    "\n",
    "prepare_ranking_summary_long(dataset1_rsf_survshap_orderings).to_csv(\"results/exp2_survshap_orderings_rsf_dataset1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('survshap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e89d17bf3f53615b213f4c00662e1677a8885f31ece09e136535e9b43ddada0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
